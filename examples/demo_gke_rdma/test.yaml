apiVersion: resource.k8s.io/v1beta1
kind: DeviceClass
metadata:
  name: dra.net
spec:
  selectors:
    - cel:
        expression: device.driver == "dra.net"
---
apiVersion: resource.k8s.io/v1beta1
kind: ResourceClaimTemplate
metadata:
  name: rdma-interfaces
spec:
  spec:
    devices:
      requests:
      - name: req-rdma-template
        deviceClassName: dra.net
        selectors:
          - cel:
              expression: device.attributes["dra.net"].cloudNetwork == "projects/455207029971/networks/map-a4-gke-rdma-net"
---
# Copyright 2024 Google Inc. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: v1
kind: Service
metadata:
  name: nccl-host-1
spec:
  selector:
    name: nccl-host-1
  clusterIP: None
---
apiVersion: v1
kind: Service
metadata:
  name: nccl-host-2
spec:
  selector:
    name: nccl-host-2
  clusterIP: None
---
apiVersion: v1
kind: Pod
metadata:
  name: nccl-test-host-1
  labels:
    name: nccl-host-1
spec:
  tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
  volumes:
    - name: library-dir-host
      hostPath:
        path: /home/kubernetes/bin/nvidia
    - name: gib
      hostPath:
        path: /home/kubernetes/bin/gib
    - name: shared-memory
      emptyDir:
        medium: "Memory"
        sizeLimit: 250Gi
  resourceClaims:
  - name: rdma
    resourceClaimTemplateName: rdma-interfaces
  containers:
    - image: us-docker.pkg.dev/gce-ai-infra/gpudirect-gib/nccl-plugin-gib-diagnostic:v1.0.5
      name: test
      resources:
        requests:
          cpu: 150m
        limits:
          nvidia.com/gpu: 1
      volumeMounts:
        - name: library-dir-host
          mountPath: /usr/local/nvidia
        - name: gib
          mountPath: /usr/local/gib
        - name: shared-memory
          mountPath: /dev/shm
      env:
        - name: LD_LIBRARY_PATH
          value: /usr/local/nvidia/lib64
      command: ["/bin/bash", "-c"]
      args:
        - |
          /scripts/container_entry.sh shell
          source /usr/local/gib/scripts/set_nccl_env.sh
          sleep infinity
---
apiVersion: v1
kind: Pod
metadata:
  name: nccl-test-host-2
  labels:
    name: nccl-host-2
spec:
  tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
  volumes:
    - name: library-dir-host
      hostPath:
        path: /home/kubernetes/bin/nvidia
    - name: gib
      hostPath:
        path: /home/kubernetes/bin/gib
    - name: shared-memory
      emptyDir:
        medium: "Memory"
        sizeLimit: 250Gi
  resourceClaims:
  - name: rdma
    resourceClaimTemplateName: rdma-interfaces
  containers:
    - image: us-docker.pkg.dev/gce-ai-infra/gpudirect-gib/nccl-plugin-gib-diagnostic:v1.0.5
      name: test
      resources:
        requests:
          cpu: 150m
        limits:
          nvidia.com/gpu: 1
      volumeMounts:
        - name: library-dir-host
          mountPath: /usr/local/nvidia
        - name: gib
          mountPath: /usr/local/gib
        - name: shared-memory
          mountPath: /dev/shm
      env:
        - name: LD_LIBRARY_PATH
          value: /usr/local/nvidia/lib64
      command: ["/bin/bash", "-c"]
      args:
        - |
          /scripts/container_entry.sh shell
          source /usr/local/gib/scripts/set_nccl_env.sh
          sleep infinity
---